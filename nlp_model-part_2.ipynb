{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhartha/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_excel(\"../Raw_data/Data_Train.xlsx\")\n",
    "df_test = pd.read_excel(\"../Raw_data/Data_Test.xlsx\")\n",
    "df_full = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Restaurant_name'] = df_full.Restaurant.apply(lambda x: x.split(\"_\")[1])\n",
    "location_encode = LabelEncoder()\n",
    "df_full['transformed_location'] = location_encode.fit_transform(df_full.Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = {\"FTI College, Law College Road, Pune\":\"Pune\",\n",
    " \"Sector 3, Marathalli\":\"Bangalore\",\n",
    " \"Mumbai Central\":\"Mumbai\",\n",
    "\"Sector 1, Noida\":\"Delhi\",\n",
    " \"Rmz Centennial, I Gate, Whitefield\":\"Bangalore\",\n",
    " \"Delhi University-GTB Nagar\":\"Delhi\",\n",
    "\"Yerawada, Pune, Maharashtra\":\"Pune\",\n",
    " \"Delhi Administration Flats, Timarpur\":\"Delhi\",\n",
    " \"Moulali, Kolkata\":\"Kolkata\",\n",
    "\"Dockyard Road, Mumbai CST Area\":\"Mumbai\",\n",
    " \"Pune University\":\"Pune\",\n",
    " \"Gora Bazar, Rajbari, North Dumdum, Kolkata\":\"Kolkata\",\n",
    "\"D-Block, Sector 63, Noida\":\"Delhi\",\n",
    " \"Sector 14, Noida\":\"Delhi\",\n",
    " \"Mico Layout, Stage 2, BTM Layout,Bangalore\":\"Bangalore\",\n",
    "\"Laxman Vihar Industrial Area, Sector 3A, Gurgoan\":\"Gurgoan\",\n",
    " \"Tiretti, Kolkata\":\"Kolkata\",\n",
    " \"Sandhurst Road, Mumbai CST Area\":\"Mumbai\",\n",
    " \"MG Road, Pune\":\"Pune\",\n",
    " \"Hyderabad Public School, Begumpet\":\"Hyderabad\",\n",
    "\"Majestic\":\"Bangalore\",\n",
    " \"Chandni Chowk, Kolkata\":\"Kolkata\",\n",
    " \"Delhi High Court, India Gate\":\"Delhi\",\n",
    "\"Chatta Bazaar, Malakpet, Hyderabad\":\"Hyderabad\",\n",
    " \"Sector 63A,Gurgaon\":\"Gurgaon\",\n",
    " \"Delhi Cantt.\":\"Delhi\",\n",
    "\"Tejas Nagar Colony, Wadala West, Mumbai\":\"Mumbai\",\n",
    " \"Babarpur, New Delhi, Delhi\":\"Delhi\",\n",
    "\"Nathan Road, Mangaldas Road, Pune\":\"Pune\",\n",
    " \"Panjetan Colony, Malakpet, Hyderabad\":\"Hyderabad\",\n",
    "\"Raja Bazar, Kolkata\":\"Kolkata\",\n",
    " \"Jaya Nagar, Saidabad, Hyderabad\":\"Hyderabad\",\n",
    " \"Noorkhan Bazaar, Malakpet, Hyderabad\":\"Hyderabad\",\n",
    "\"Musi Nagar, Malakpet, Hyderabad\":\"Hyderabad\",\n",
    " \"BTM Layout 1, Electronic City\":\"Bangalore\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['City'] = df_full.Location.map(city)\n",
    "city_enc =LabelEncoder()\n",
    "df_full['City'] = city_enc.fit_transform(df_full.City)\n",
    "df_full['Count_cuisins'] = df_full.Cuisines.apply(lambda x: len(x.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a list of final cuisins \n",
    "\n",
    "cuisines = []\n",
    "for i in df_full.Cuisines.values:\n",
    "    try:\n",
    "        cuisines.append(i.split(\",\"))\n",
    "    except:\n",
    "        cuisines.append(i)\n",
    "cuisines_cleaned = []\n",
    "for i in cuisines:\n",
    "    cuisines_cleaned+=i\n",
    "    \n",
    "final_cuisins = []\n",
    "for i in list(set(cuisines_cleaned)):\n",
    "    text = re.findall(r'\\w+',i)\n",
    "    text = (\" \").join(text)\n",
    "    final_cuisins.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = dict(zip(set(final_cuisins),[i for i in range (len(set(final_cuisins)))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuisine_clear(cuisine):\n",
    "    global map_dict\n",
    "    cuisines = []\n",
    "    try:\n",
    "        cuisines.append(cuisine.split(\",\"))\n",
    "    except:\n",
    "        cuisines.append(cuisine)\n",
    "    \n",
    "    cuisines_cleaned = []\n",
    "    for i in cuisines:\n",
    "        cuisines_cleaned+=i\n",
    "    final_cuisins = []\n",
    "    for i in list(set(cuisines_cleaned)):\n",
    "        text = re.findall(r'\\w+',i)\n",
    "        text = (\" \").join(text)\n",
    "        for i,k in  map_dict.items():\n",
    "            if i == text:\n",
    "                final_cuisins.append(k)\n",
    "    return sum(final_cuisins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Cuisines_enc'] = df_full.Cuisines.apply(cuisine_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=text.lower()\n",
    "    text = re.sub(r'@[a-zA-Z0-9_]+', '', text)\n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)\n",
    "    text = re.sub(r'www.[^ ]+', '', text)\n",
    "    text = re.sub(r'[a-zA-Z0-9]*www[a-zA-Z0-9]*com[a-zA-Z0-9]*', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = [token for token in text.split() if len(token) > 2]\n",
    "    text = ' '.join(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Cuisines'] = df_full['Cuisines'].apply(clean_text)\n",
    "df_full.Location = df_full.Location.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(ngram_range=(1, 1), lowercase=False)\n",
    "train_route = tf.fit_transform(df_full['Cuisines'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_route = pd.DataFrame(data=train_route.toarray(), columns=tf.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afghan</th>\n",
       "      <th>african</th>\n",
       "      <th>american</th>\n",
       "      <th>andhra</th>\n",
       "      <th>arabian</th>\n",
       "      <th>asian</th>\n",
       "      <th>assamese</th>\n",
       "      <th>awadhi</th>\n",
       "      <th>bakery</th>\n",
       "      <th>bangladeshi</th>\n",
       "      <th>...</th>\n",
       "      <th>sushi</th>\n",
       "      <th>tamil</th>\n",
       "      <th>tea</th>\n",
       "      <th>tex</th>\n",
       "      <th>thai</th>\n",
       "      <th>tibetan</th>\n",
       "      <th>turkish</th>\n",
       "      <th>vietnamese</th>\n",
       "      <th>wraps</th>\n",
       "      <th>yogurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578626</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   afghan  african  american  andhra  arabian  asian  assamese  awadhi  \\\n",
       "0     0.0      0.0       0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "1     0.0      0.0       0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "2     0.0      0.0       0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "3     0.0      0.0       0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "4     0.0      0.0       0.0     0.0      0.0    0.0       0.0     0.0   \n",
       "\n",
       "   bakery  bangladeshi  ...  sushi  tamil  tea  tex  thai  tibetan  turkish  \\\n",
       "0     0.0          0.0  ...    0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "1     0.0          0.0  ...    0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "2     0.0          0.0  ...    0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "3     0.0          0.0  ...    0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "4     0.0          0.0  ...    0.0    0.0  0.0  0.0   0.0      0.0      0.0   \n",
       "\n",
       "   vietnamese     wraps  yogurt  \n",
       "0         0.0  0.578626     0.0  \n",
       "1         0.0  0.000000     0.0  \n",
       "2         0.0  0.000000     0.0  \n",
       "3         0.0  0.000000     0.0  \n",
       "4         0.0  0.000000     0.0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_route.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = list(df_full.columns)\n",
    "col_2 = list(train_route.columns)\n",
    "\n",
    "col_1.extend(col_2)\n",
    "df_full = pd.concat([df_full.reset_index(drop=True),train_route], axis=1,ignore_index=True)\n",
    "df_full.columns= col_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tf = TfidfVectorizer(ngram_range=(1, 1), lowercase=False)\n",
    "# train_route = tf.fit_transform(df_full['Location'])\n",
    "# train_route = pd.DataFrame(data=train_route.toarray(), columns=tf.get_feature_names())\n",
    "\n",
    "# col_1 = list(df_full.columns)\n",
    "# col_2 = list(train_route.columns)\n",
    "\n",
    "# col_1.extend(col_2)\n",
    "# df_full = pd.concat([df_full.reset_index(drop=True),train_route], axis=1,ignore_index=True)\n",
    "# df_full.columns= col_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full['Location_length_string'] = df_full.Location.apply(lambda x: len(x.split(\" \"))).astype(int)\n",
    "# df_full['Cuisine_string_length'] = df_full.Cuisines.apply(lambda x: len(x.split(\" \"))).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df_full = df_full[df_full['Average_Cost']!='for']\n",
    "df_full['Average_Cost'] = df_full['Average_Cost'].apply(lambda x: re.findall(r\"\\d+\",x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['Minimum_Order'] = df_full['Minimum_Order'].apply(lambda x: re.findall(r\"\\d+\",x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = ['-','NEW','Opening Soon','Temporarily Closed']\n",
    "val1 = ['-']\n",
    "val2 = ['Opening Soon','Temporarily Closed']\n",
    "\n",
    "df_full.Rating = df_full.Rating.apply(lambda x:np.nan if x in val else float(x) )\n",
    "def missing_value_rating(df):\n",
    "    df.Rating = df.Rating.fillna(df.Rating.mean())\n",
    "    return df\n",
    "\n",
    "df_full = df_full.groupby(\"transformed_location\").apply(missing_value_rating)\n",
    "df_full.Rating = df_full.Rating.fillna(df_full.Rating.mean())\n",
    "\n",
    "\n",
    "def missing_votes(df):\n",
    "    df.Votes = df.Votes.fillna(df.Votes.mean()) \n",
    "    return df\n",
    "\n",
    "df_full.Votes = df_full.Votes.apply(lambda x:np.nan if x=='-' else float(x) )\n",
    "# # df_full.Votes = df_full.Votes.fillna(int(df_full.Votes.mean()))\n",
    "\n",
    "df_full =df_full.groupby(\"transformed_location\").apply(missing_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_reviews(df):\n",
    "    df.Reviews = df.Reviews.fillna(df.Reviews.mean()) \n",
    "    return df\n",
    "df_full.Reviews = df_full.Reviews.apply(lambda x:np.nan if x=='-' else float(x))\n",
    "df_full =df_full.groupby(\"City\").apply(missing_votes)\n",
    "df_full.Reviews = df_full.Reviews.fillna(df_full.Reviews.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.loc[:,~df_full.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop(['Restaurant', 'Location','Cuisines'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_full[df_full.Delivery_Time.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.Average_Cost = df_full.Average_Cost.astype(int)\n",
    "df_full.Minimum_Order = df_full.Minimum_Order.astype(int)\n",
    "df_full.Restaurant_name = df_full.Restaurant_name.astype(int)\n",
    "df_full.transformed_location = df_full.transformed_location.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_time_encode = LabelEncoder()\n",
    "del_time_encode.fit(df_full.Delivery_Time)\n",
    "df_full.Delivery_Time = del_time_encode.transform(df_full.Delivery_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_full.drop(\"Delivery_Time\",axis = 1)\n",
    "Y = df_full.Delivery_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC = RandomForestClassifier(n_estimators=1000,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.800811176205498"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(RC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhartha/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([6.36495256, 4.62283087, 4.65142035, 4.60709715, 4.65814662]),\n",
       " 'score_time': array([0.40925217, 0.3067739 , 0.30709672, 0.30597687, 0.30603623]),\n",
       " 'test_score': array([0.7954955 , 0.79144144, 0.80396575, 0.78764653, 0.79196751])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(RC,X,Y,error_score='accuracy',cv= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recv = RFECV(RC,step= 10,min_features_to_select=50,scoring='accuracy',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = X_train.iloc[:,recv.get_support(indices=True)]\n",
    "# X_test = X_test.iloc[:,recv.get_support(indices=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params= {'n_estimators' : [500,700,900,1000,1200],\n",
    "#          'max_depth':[50,100,200,300,400],\n",
    "#          'learning_rate': [0.1,0.01,0.05,0.2],\n",
    "#          'min_child_weight':[0.1,0.01,0.001,1,2],\n",
    "#          'max_delta_step':[40,50,80,100],\n",
    "#          'reg_alpha':[1,0.1,0.3,0.01],\n",
    "#          'reg_lambda':[1,0.1,5],\n",
    "#          'n_jobs':[2]\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rscv = RandomizedSearchCV(xgb,scoring = 'accuracy',param_distributions=params,verbose=1,n_iter=30,n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhartha/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/home/sidhartha/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 131.9min\n"
     ]
    }
   ],
   "source": [
    "# rscv.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rscv.best_estimator_.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=rscv.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=1500,learning_rate=0.01,max_depth=410,n_jobs=-1,min_child_weight=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=410,\n",
       "              min_child_weight=0.01, missing=None, n_estimators=1500, n_jobs=-1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156827399729608"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7661108607480848"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(n_estimators=500,num_leaves=50,learning_rate=0.01)\n",
    "lgbm.fit(X_train,y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=410,\n",
       "              min_child_weight=0.01, missing=None, n_estimators=1500, n_jobs=-1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.Average_Cost = df_test.Average_Cost.astype(int)\n",
    "df_test.Minimum_Order = df_test.Minimum_Order.astype(int)\n",
    "df_test.Restaurant_name = df_test.Restaurant_name.astype(int)\n",
    "df_test.transformed_location = df_test.transformed_location.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(df_test.drop(\"Delivery_Time\",axis=1)[X.columns])\n",
    "df_submit = pd.DataFrame({\"Delivery_Time\":del_time_encode.inverse_transform(y_pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_excel(\"submit.xlsx\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
